---
title: "p8105_hw3_ak4123"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r question 1 data cleaning }
library(p8105.datasets)
data("brfss_smart2010")

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  filter(response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(response = ordered(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor")))
```

```{r question 1 questions}
brfss_data %>%
  filter(year == 2002) %>% 
  distinct(locationdesc, locationabbr) %>%
  group_by(locationabbr) %>% 
  count() %>% 
  filter(n == 7)

brfss_data %>% 
  filter(year >= 2002 & year <= 2010) %>% 
  group_by(locationabbr, year) %>%  
  distinct(locationdesc) %>% 
  summarize(location_count = n()) %>%
  ggplot(aes(x = year, y = location_count, color = locationabbr)) +
    geom_line(size = 0.1) +
    labs(
      title = "Observation Plot",
      x = "Year",
      y = "Number of Observations",
      caption = "BRFSS Data"
    ) +
    viridis::scale_color_viridis(
      name = "State",
      discrete = TRUE
    ) + 
  guides(color = guide_legend(nrow = 6))

brfss_data %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>% 
  select(year, excellent, locationabbr) %>% 
  filter(!is.na(excellent) & locationabbr == "NY" & (year == "2002" | year == "2006" | year == "2010")) %>%
  group_by(year) %>% 
  summarize(mean_proportion_excellent = mean(excellent), sd_proportion_excellent = sd(excellent)) %>% 
  knitr::kable()
##need to edit this because I do not think the proportion is right

brfss_data %>% 
  mutate(proportion = data_value / 100) %>% 
  group_by(year, locationabbr, response) %>% 
  summarize(mean_proportion = mean(proportion)) %>% 
  ggplot(aes(x = year, y = mean_proportion, color = locationabbr)) +
    geom_point(alpha = 0.5) +
    scale_x_continuous(breaks = c(2003, 2006, 2009)) +
    facet_grid(~response) +
    labs(
      title = "Response to Overall Health Question: Broken Down By State for the years 2002 to 2010",
      x = "Year", 
      y = "Mean Proportion",
      caption = "BRFSS Data"
    ) +
    viridis::scale_color_viridis(
      name = "State",
      discrete = TRUE
    )+
    guides(color = guide_legend(nrow = 6))


```


```{r question 2 cleaning}
library(p8105.datasets)
data("instacart")

instacart = instacart %>% 
janitor::clean_names()
```
The dimensions of this dataset are (`r {dim(instacart)}`). This means there are 1384617 observations (rows) and 15 variables (columns). Some of the key variables include the order identification number, product name (along with an identification number), the department and aisle the product is located in. There is also...
"order_id"               "product_id"            
 [3] "add_to_cart_order"      "reordered"             
 [5] "user_id"                "eval_set"              
 [7] "order_number"           "order_dow"             
 [9] "order_hour_of_day"      "days_since_prior_order"
[11] "product_name"           "aisle_id"              
[13] "department_id"          "aisle"                 
[15] "department"        

## give illustrative examples of observataions.
```{r}

##the aisles with the most orders
instacart %>% 
group_by(aisle) %>% 
  count(order_id) %>% 
arrange(desc(n)) %>% 
  head(7)

```
There are `r {instacart %>% 
  distinct(aisle) %>% 
count()}` aisle. 

###THE MOST ORDERS NEED TO FIX THIS 
aisle               order_id     n
  <chr>                  <int> <int>
1 baby food formula    2188545    28
2 energy granola bars  1385776    28
3 tea                  2445873    27
4 yogurt               2606705    26
5 cat food care        3363902    24
6 energy granola bars  2397010    24
7 baby food formula    2070470    23

```{r question 2 plots}

instacart %>% 
  group_by(aisle) %>% 
  summarize(amount_ordered = n()) %>% 
  ggplot(aes(x = aisle, y = amount_ordered)) + 
  geom_point() +
  labs(
     title = "Items ordered in each aisle",
     x = "aisle number",
     y = "number of items ordered"
    )

instacart %>% 
  filter(aisle == "baking ingredients" | aisle == 
           "dog food care" | aisle == "packaged vegetables fruits") %>% 
  group_by(product_name, aisle) %>% 
  summarize(most_ordered = n()) %>% 
arrange(desc(most_ordered)) %>% 
group_by(aisle) %>% 
  top_n( n = 1, wt = most_ordered) %>% 
  select(aisle, product_name, most_ordered) %>% 
  rename(top_product_name = product_name) %>% 
  arrange(aisle) %>% 
  knitr::kable()


instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name ==  "Coffee Ice Cream") %>% 
select(order_hour_of_day, order_dow, product_name) %>% 
group_by(product_name, order_dow) %>% 
summarize(mean_hour = mean(order_hour_of_day)) %>% 
spread(key = order_dow, value = mean_hour)
```

```{r question 3 data import}
library(p8105.datasets)
data("ny_noaa") 
```

The dimensions of this dataset are (`r {dim(ny_noaa)}`). This means there are 2595176 observations (rows) and 7 variables (columns). Some of the key variables include "id"   "date" "prcp" "snow" "snwd" "tmax" "tmin"
MISSING DATA IS AN ISSUE BC ...

```{r question 3 data cleaning}
ny_noaa = ny_noaa %>%
janitor::clean_names() %>% 
separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(precipitation = prcp / 10, tmax = as.integer(tmax) / 10, tmin = as.integer(tmin) / 10)
```

```{r questions}
ny_noaa %>% 
  group_by(snow) %>% 
  summarize(freq = n()) %>% 
  arrange(desc(freq)) %>% 
  head(7)


```